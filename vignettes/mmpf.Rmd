---
title: "Monte-Carlo Methods for Prediction Functions"
author: "Zachary M. Jones"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Monte-Carlo Methods for Prediction Functions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```

This packages allows you to to marginalize arbitrary prediction functions using Monte-Carlo integration. Since many prediction functions cannot be easily decomposed into a sum of low dimensional components marginalization can be helpful in making these functions interpretable.

`marginalPrediction` does this computation and then evaluates the marginalized function at a set grid points, which can be uniformly created, subsampled from the training data, or explicitly specified as an argument.

The create of a uniform grid is handled by the `variableGrid` method. If `uniform = FALSE` and the `points` argument isn't used to specify what points to evaluate, a sample of size `n[1]` is taken from the data without replacement.

```{r}
library(mmpf)
library(randomForest)

data(swiss)

fit = randomForest(Fertility ~ ., swiss)
marginalPrediction(swiss[, -1], "Education", c(10, 25), fit)
```

The output of `marginalPrediction` is always a list with two elements, `prediction` and `points`.

By default the Monte-Carlo expectation is computed, which is set by the `aggregate.fun` argument's default value, the `mean` function. Substituting, say, the median, would give a different output.

```{r}
marginalPrediction(swiss[, -1], "Education", c(10, 25), fit, aggregate.fun = identity)
````

By passing the identity function to `aggregate.fun`, which simply returns its input exactly, the integration points are returned directly so that the `prediction` element of the return is a matrix of dimension `n`.

`marginalPrediction` can also handle cases in which predictions for a single data point are vector-valued. That is, classification tasks where probabilities are output, and multivariate regression and/or classification. In these cases `aggregate.fun` is applied separately to each column of the prediction matrix.

```{r}
data(iris)

fit = randomForest(Species ~ ., iris)
marginalPrediction(iris[, -ncol(iris)], "Sepal.Width", c(10, 25), fit,
  predict.fun = function(object, newdata) predict(object, newdata = newdata, type = "prob"))
```

In all of the aforementioned cases `vars` can include multiple variables. In this case the Cartesian product of each variable's grid is taken (however that is created), resulting in an at-most `n[1]^length(vars)` unique points. This number can be reduced if `n[1]` is less than the unique number of values for one of the variables.

```{r}
marginalPrediction(iris[, -ncol(iris)], c("Sepal.Width", "Sepal.Length"), c(5, 25), fit,
  predict.fun = function(object, newdata) predict(object, newdata = newdata, type = "prob"))
```

Permutation importance is a Monte-Carlo method which estimates the importance of variables in determining predictions by computing the change from repeatedly permuting the values of those variables, and comparing the prediction error using the permuted data to the error on the unpermuted training data.

`permutationImportance` can compute this type of importance under arbitrary loss (with respect to the observed target) functions and contrast (between the loss with the unpermuted and permuted data).


```{r}
permutationImportance(iris, "Sepal.Width", "Species", fit)
```

For methods which generate predictions which are characters or unordered factors, the default loss function is the mean misclassification error. For all other types of predictions mean squared error is used.

It is, for example, possible to compute the expected change in the mean misclassification rate by class. The two arguments to `loss.fun` are the permuted predictions and the target variable. In this case they are both vectors of factors.

```{r}
permutationImportance(iris, "Sepal.Width", "Species", fit,
  loss.fun = function(x, y) {
    mat = table(x, y)
    n = colSums(mat)
    diag(mat) = 0
    rowSums(mat) / n
  },
  contrast.fun = function(x, y) x - y)
```
